{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이토치 기초 문법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.],\n",
       "        [ 1., -1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1., -1.], [1., -1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# print(torch.tensor([[1,2], [3,4]]))\n",
    "# print(torch.tensor([[1,2], [3,4]], device='cuda:0') )\n",
    "print(torch.tensor([[1,2], [3,4]], dtype=torch.float64) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "---------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "---------------------\n",
      "tensor([1, 2, 3, 4])\n",
      "---------------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "---------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "print(temp.shape)\n",
    "print('---------------------')\n",
    "print(temp.view(4,1))\n",
    "print('---------------------')\n",
    "print(temp.view(-1))\n",
    "print('---------------------')\n",
    "print(temp.view(1,-1))\n",
    "print('---------------------')\n",
    "print(temp.view(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINIST 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(in_features=1, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer = nn.Linear(inputs, 1) # 계층 정의\n",
    "        self.activation = nn.sigmoid # 활성화함수 정의\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.layer(X)\n",
    "        X = self.activation(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing Children\n",
      "---------------------\n",
      "[Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      ")]\n",
      "printing Modules\n",
      "---------------------\n",
      "[MLP(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "model = MLP()\n",
    "\n",
    "print('printing Children\\n---------------------')\n",
    "print(list(model.children()))\n",
    "print('printing Modules\\n---------------------')\n",
    "print(list(model.modules()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "batch_size = 64\n",
    "epoch = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1.0,)) # 평균이 0.5, 표준편차가 1.0이 되도록 데이터의 분포(normalize)를 조정\n",
    "])\n",
    "\n",
    "download_root = '/home/xogns5037/Basic_PyTorch/data'\n",
    "\n",
    "# 훈련 & 검증 & 데이터셋 \n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "# 데이터 로더 (train과 valid, test 배치 사이즈 달라도 크게 상관없음)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # layer 정의\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) # 2차원 -> 1차원으로 변환\n",
    "        # x = self.fc1(x)\n",
    "        # x = torch.relu(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer, loss function 설정\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1300\n",
      "Epoch 2, Loss: 0.4743\n",
      "Epoch 3, Loss: 0.0360\n",
      "Epoch 4, Loss: 0.0998\n",
      "Epoch 5, Loss: 0.0652\n",
      "Epoch 6, Loss: 0.0525\n",
      "Epoch 7, Loss: 0.1958\n",
      "Epoch 8, Loss: 0.0729\n",
      "Epoch 9, Loss: 0.0075\n",
      "Epoch 10, Loss: 0.0165\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습(CPU)\n",
    "for i in range(epoch):\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        preds = model(images) # 모델 예측\n",
    "        loss = loss_fn(preds, labels) # loss 계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 가중치 업데이트\n",
    "    \n",
    "    print(f'Epoch {i+1}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3778\n",
      "Epoch 2, Loss: 0.1148\n",
      "Epoch 3, Loss: 0.0784\n",
      "Epoch 4, Loss: 0.0409\n",
      "Epoch 5, Loss: 0.0130\n",
      "Epoch 6, Loss: 0.0856\n",
      "Epoch 7, Loss: 0.0879\n",
      "Epoch 8, Loss: 0.0384\n",
      "Epoch 9, Loss: 0.1699\n",
      "Epoch 10, Loss: 0.0072\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습(GPU)\n",
    "\n",
    "# GPU 디바이스 설정\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저를 디바이스로 이동\n",
    "model = SimpleNN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "for i in range(epoch):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        preds = model(images)  # 모델 예측\n",
    "        loss = loss_fn(preds, labels)  # 손실 계산\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()  # 가중치 업데이트\n",
    "    \n",
    "    # 에포크당 손실 출력\n",
    "    print(f'Epoch {i+1}, Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on test dataset: 96.86%\n"
     ]
    }
   ],
   "source": [
    "# model valid\n",
    "model.eval()  # 모델을 평가 모드로 설정 = 파라미터 업데이트 X\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# GPU 디바이스 설정\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with torch.no_grad(): # 기울기 계산 비활성화\n",
    "    for images, labels in test_loader:\n",
    "        preds = model(images) # 모델 예측\n",
    "        _, predicted = torch.max(preds.data, 1)\n",
    "        total += labels.size(0) # 전체 샘플 수\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = (correct / total) * 100\n",
    "print(f'Accuracy of the model on test dataset: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1889, Accuracy: 92.26%\n",
      "Epoch 2, Loss: 0.2389, Accuracy: 94.11%\n",
      "Epoch 3, Loss: 0.1773, Accuracy: 95.80%\n",
      "Epoch 4, Loss: 0.2362, Accuracy: 96.37%\n",
      "Epoch 5, Loss: 0.0435, Accuracy: 96.51%\n",
      "Epoch 6, Loss: 0.0077, Accuracy: 97.06%\n",
      "Epoch 7, Loss: 0.0129, Accuracy: 96.75%\n",
      "Epoch 8, Loss: 0.0216, Accuracy: 97.06%\n",
      "Epoch 9, Loss: 0.0816, Accuracy: 97.27%\n",
      "Epoch 10, Loss: 0.0522, Accuracy: 97.23%\n",
      "Accuracy of the model on test dataset: 97.23%\n"
     ]
    }
   ],
   "source": [
    "# 한 epoch이 끝날때마다 valuation을 수행하고, 전체 수행 후 test data에 대한 accuracy를 출력\n",
    "\n",
    "# GPU 디바이스 설정\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저를 디바이스로 이동\n",
    "model = SimpleNN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "for i in range(epoch):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        preds = model(images)  # 모델 예측\n",
    "        loss = loss_fn(preds, labels)  # 손실 계산\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()  # 가중치 업데이트\n",
    "    \n",
    "    # 에포크당 validation 수행\n",
    "    with torch.no_grad():  # 기울기 계산 비활성화\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images)\n",
    "            _, predicted = torch.max(preds.data, 1)            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        accuracy = (correct / total) * 100\n",
    "        print(f'Epoch {i+1}, Loss: {loss.item():.4f}, Val Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "# 모델 평가\n",
    "model.eval()  # 모델을 평가 모드로 설정 = 파라미터 업데이트 X\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad(): # 기울기 계산 비활성화\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images) # 모델 예측\n",
    "        _, predicted = torch.max(preds.data, 1)\n",
    "        total += labels.size(0) # 전체 샘플 수\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "accuracy = (correct / total) * 100\n",
    "print(f'Accuracy of the model on test dataset: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 합성곱 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /home/xogns5037/Basic_PyTorch/data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='/home/xogns5037/Basic_PyTorch/data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='/home/xogns5037/Basic_PyTorch/data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt', 7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN vs CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "\n",
    "class FashionDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=28*28, out_features=256)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=10)\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        out = input_data.view(-1, 28*28)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionDNN(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "model = FashionDNN()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.5764753818511963, Accuracy: 83.27999877929688\n",
      "Iteration: 1000, Loss: 0.44199612736701965, Accuracy: 84.91999816894531\n",
      "Iteration: 1500, Loss: 0.3234631419181824, Accuracy: 84.47000122070312\n",
      "Iteration: 2000, Loss: 0.37893372774124146, Accuracy: 85.50999450683594\n",
      "Iteration: 2500, Loss: 0.2274029403924942, Accuracy: 85.86000061035156\n",
      "Iteration: 3000, Loss: 0.2534821927547455, Accuracy: 87.00999450683594\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        train = Variable(images.view(100, 1, 28, 28)) \n",
    "        labels = Variable(labels)\n",
    "        # Variable은 torch.Tensor를 감싸고, 계산 그래프를 만들어줌, 하지만 0.4.0 버전 이후로는 불필요\n",
    "        \n",
    "        outputs = model(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50):\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "                \n",
    "                outputs = model(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels)\n",
    "                \n",
    "            accuracy = correct * 100 / total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500):\n",
    "            print(f'Iteration: {count}, Loss: {loss.data}, Accuracy: {accuracy}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
      "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.22716039419174194, Accuracy: 89.54000091552734\n",
      "Iteration: 1000, Loss: 0.1563497930765152, Accuracy: 90.79999542236328\n",
      "Iteration: 1500, Loss: 0.26320797204971313, Accuracy: 90.55999755859375\n",
      "Iteration: 2000, Loss: 0.17619465291500092, Accuracy: 90.80999755859375\n",
      "Iteration: 2500, Loss: 0.20892852544784546, Accuracy: 91.39999389648438\n",
      "Iteration: 3000, Loss: 0.14919129014015198, Accuracy: 89.65999603271484\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 5\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = [] \n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        train = Variable(images.view(100, 1, 28, 28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        outputs = model(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50):\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "                outputs = model(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels)\n",
    "                \n",
    "            accuracy = correct * 100 / total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500):\n",
    "            print(f'Iteration: {count}, Loss: {loss.data}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
